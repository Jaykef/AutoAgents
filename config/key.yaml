# Configuration for SerpAPI
SERPAPI_API_KEY: "c8a3d4e9381549a9d0303424dfb1800fbf98391630205293a0f9fb045351d988"

# Configuration for llama.cpp server using local gguf model
LLAMA_CPP_SERVER_URL: "http://localhost:8080"
GGUF_MODEL_PATH: "/home/ubuntu/TinyLlama-1.1B-Chat-v1.0-GGUF/tinyllama-1.1b-chat-v1.0.Q4_0.gguf"
